{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://gist.githubusercontent.com/jakubczakon/10e5eb3d5024cc30cdb056d5acd3d92f/raw/5c464c16ccbc7150b4025e0a2a05b84ab99a7bc3/logo_DS_AI.png\" alt=\"Drawing\" width=\"600\"/>\n",
    "\n",
    "# deepsense.ai's workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. *k* nearest neighbors (bikes)\n",
    "\n",
    "In this notebook we use the *k* nearest neighbors algorithm to predict whether a day is a winter day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, let us use the Bike Sharing Dataset\n",
    "df = pd.read_csv(\"data/Bike-Sharing-Dataset/day.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### warning: official description was wrong!\n",
    "seasons = {1: \"winter\", 2: \"spring\", 3: \"summer\", 4: \"fall\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recoding seasons\n",
    "df['season'] = df['season'].map(seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by \"seasons\", selecting \"cnt\" columns and then taking mean \n",
    "df.groupby(\"season\")[\"cnt\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define some colors we will be using\n",
    "colors = {\"winter\": \"#5555dd\", \"spring\": \"#55dd55\", \"summer\": \"#fcc969\", \"fall\": \"#dd5555\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "# temperatures in seasons\n",
    "for name, df_part in df.groupby(\"season\")[\"temp\"]:\n",
    "    sns.distplot(df_part, hist=False, label=name, color=colors[name], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "* Plot humidity by season.\n",
    "* Plot casual and (on a separate plot) registered rentals by season.\n",
    "* ★ Plot total usage by weekday.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random split into train and test set is not a good idea here. Why?\n",
    "\n",
    "Instead, we take data from 2011 to the train set and from 2012 to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df.dteday), max(df.dteday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = df.dteday < '2012-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[train_mask]\n",
    "df_test = df[~train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *k* Nearest Neighbors for 3 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* What's the accuracy of the best constant model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's predict whether the season is winter\n",
    "\n",
    "feature_1 = \"temp\"\n",
    "feature_2 = \"casual\"\n",
    "\n",
    "# input\n",
    "X_train = df_train[[feature_1, feature_2]]\n",
    "X_test = df_test[[feature_1, feature_2]]\n",
    "\n",
    "# output\n",
    "Y_train = df_train[\"season\"] == \"winter\"\n",
    "Y_test = df_test[\"season\"] == \"winter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_train.assign(winter=Y_train)\n",
    "# we could do the same with data by typing:\n",
    "# data = X_train.copy()\n",
    "# data['winter'] = Y_train\n",
    "\n",
    "sns.lmplot(x=feature_1, y=feature_2, data=data, fit_reg=False, hue=\"winter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=feature_1, y=feature_2, data=X_test, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "- We need to normalize data to put data with no misleading information to the model.\n",
    "- We transform data so that each feature for the training set has the mean equal to 0 and the standard deviation equal to 1.\n",
    "- Note that we transform both train and test data with use of the same statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X_train.mean()\n",
    "s = X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - m) / s\n",
    "X_test = (X_test - m) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "* We can normalize data 'on the fly' in two lines of code. How to do that? Only one of the three propositions below is correct. Which one and why?\n",
    "  * Proposition A\n",
    "  ```\n",
    "  X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "  X_test = (X_test - X_test.mean()) / X_test.std()\n",
    "  ```\n",
    "  \n",
    "  * Proposition B\n",
    "  ```\n",
    "  X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "  X_test = (X_test - X_train.mean()) / X_train.std()\n",
    "  ```\n",
    "  \n",
    "  * Proposition C\n",
    "  ```\n",
    "  X_test = (X_test - X_train.mean()) / X_train.std()\n",
    "  X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "  ```\n",
    "* Data can be normalized in other ways as well. One of commonly used solutions is to squeeze data into a standard interval.\n",
    "  * What `m` and `s` should we choose to squeeze training data into interval `[0,1]`?\n",
    "  * ★ What `m` and `s` should we choose to squeeze training data into interval `[-1,1]`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_train.assign(winter=Y_train)\n",
    "sns.lmplot(x=feature_1, y=feature_2, data=data, fit_reg=False, hue=\"winter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=feature_1, y=feature_2, data=X_test, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a knn classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training KNN model on data\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score - percent of correct answers\n",
    "# on the train set\n",
    "knn.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score - percent of correct answers\n",
    "# on the test set\n",
    "knn.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check some other k\n",
    "test_score_list = []\n",
    "k_list = range(1, 201)\n",
    "\n",
    "for k in k_list:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    test_score_list.append(knn.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best k and best score\n",
    "k_list[np.argmax(test_score_list)], test_score_list[np.argmax(test_score_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x=k_list, y=test_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "* What is the score for *k* around 200 and why? Answer without computations.\n",
    "* What is the smallest *k* for which the score is the same as for 200 and why? Answer without computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's check for n=41\n",
    "knn = KNeighborsClassifier(n_neighbors=41)\n",
    "# training Linear Regression on data\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "* ★ Plot the scores for *k* between 75 and 100. Why does the plot form a 'ridge'?\n",
    "* Repeat the procedure, but this time use `registered` instead of `temp`. Analyze the results.\n",
    "* ★ Repeat the procedure for distance L1 instead of L2. Compare the results.\n",
    "* ★★ Plot the decision boundaries.\n",
    "* ★ We chose 'the best' *k* using the score on the test set. Is that reasonable?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
